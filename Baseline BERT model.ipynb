{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 128 # sequence length\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ae1be9d01d47a0ae4fabc784c15aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18108), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/train.json', 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "rows = []\n",
    "for i in tqdm(range(len(data))):\n",
    "    obj = data[i]\n",
    "    rows.append({'question': obj['question'], 'text': obj['text'], 'label': obj['label']})\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = list(df['question'].values)\n",
    "texts = list(df['text'].values)\n",
    "labels = df['label'].values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bacb155461408ab6009f9a135f789f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "sentence_masks = []\n",
    "attention_masks = []\n",
    "\n",
    "for question, text in tqdm(zip(questions, texts)):\n",
    "    input_dict = tokenizer.encode_plus(question, text, add_special_tokens=True, max_length=SEQ_LEN)\n",
    "    token, sentence_mask = input_dict['input_ids'], input_dict['token_type_ids']\n",
    "    \n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
    "    attention_mask = [1] * len(token)\n",
    "    \n",
    "    # Zero-pad up to the sequence length.\n",
    "    padding_length = SEQ_LEN - len(token)\n",
    "    token = token + ([0] * padding_length)\n",
    "    attention_mask = attention_mask + ([0] * padding_length)\n",
    "    sentence_mask = sentence_mask + ([0] * padding_length)\n",
    "    \n",
    "    tokens.append(token)\n",
    "    sentence_masks.append(sentence_mask)\n",
    "    attention_masks.append(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.array(tokens)\n",
    "sentence_masks = np.array(sentence_masks)\n",
    "attention_masks = np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train, tokens_val, \\\n",
    "sentence_masks_train, sentence_masks_val, \\\n",
    "attention_masks_train, attention_masks_val, \\\n",
    "labels_train, labels_val = train_test_split(tokens, sentence_masks, attention_masks, labels, \n",
    "                                             test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ({'input_ids': tokens_train, 'attention_mask': attention_masks_train, 'token_type_ids': sentence_masks_train}, \n",
    "              labels_train)\n",
    "val_data = ({'input_ids': tokens_val, 'attention_mask': attention_masks_val, 'token_type_ids': sentence_masks_val}, \n",
    "              labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
    "# model = TFBertForSequenceClassification.from_pretrained('./model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=3, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16297 samples, validate on 1811 samples\n",
      "Epoch 1/10\n",
      "16297/16297 [==============================] - 823s 50ms/sample - loss: 0.4300 - accuracy: 0.8040 - val_loss: 0.3611 - val_accuracy: 0.8421\n",
      "Epoch 2/10\n",
      "16297/16297 [==============================] - 808s 50ms/sample - loss: 0.2952 - accuracy: 0.8800 - val_loss: 0.3710 - val_accuracy: 0.8520\n",
      "Epoch 3/10\n",
      "16297/16297 [==============================] - 800s 49ms/sample - loss: 0.2155 - accuracy: 0.9135 - val_loss: 0.3388 - val_accuracy: 0.8719\n",
      "Epoch 4/10\n",
      "16297/16297 [==============================] - 807s 50ms/sample - loss: 0.1467 - accuracy: 0.9461 - val_loss: 0.4252 - val_accuracy: 0.8570\n",
      "Epoch 5/10\n",
      "16297/16297 [==============================] - 798s 49ms/sample - loss: 0.1129 - accuracy: 0.9580 - val_loss: 0.4434 - val_accuracy: 0.8415\n",
      "Epoch 6/10\n",
      "16290/16297 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9649Restoring model weights from the end of the best epoch.\n",
      "16297/16297 [==============================] - 801s 49ms/sample - loss: 0.0961 - accuracy: 0.9649 - val_loss: 0.6121 - val_accuracy: 0.8592\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate using tf.keras.Model.fit()\n",
    "history = model.fit(x=train_data[0], y=train_data[1], \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                    callbacks=[early_stop], validation_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.predict(val_data[0])\n",
    "probs = tf.math.softmax(logits).numpy()\n",
    "threshold_range = np.arange(0.5, 1.0, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction threshold = 0.50 - Validation accuracy: 87.1894% - Validation f1 score: 0.7895\n",
      "Prediction threshold = 0.55 - Validation accuracy: 86.9133% - Validation f1 score: 0.7787\n",
      "Prediction threshold = 0.60 - Validation accuracy: 87.0790% - Validation f1 score: 0.7780\n",
      "Prediction threshold = 0.65 - Validation accuracy: 86.9133% - Validation f1 score: 0.7710\n",
      "Prediction threshold = 0.70 - Validation accuracy: 86.2507% - Validation f1 score: 0.7542\n",
      "Prediction threshold = 0.75 - Validation accuracy: 85.6985% - Validation f1 score: 0.7371\n",
      "Prediction threshold = 0.80 - Validation accuracy: 84.8150% - Validation f1 score: 0.7090\n",
      "Prediction threshold = 0.85 - Validation accuracy: 83.6002% - Validation f1 score: 0.6747\n",
      "Prediction threshold = 0.90 - Validation accuracy: 82.8824% - Validation f1 score: 0.6501\n",
      "Prediction threshold = 0.95 - Validation accuracy: 81.2258% - Validation f1 score: 0.6000\n"
     ]
    }
   ],
   "source": [
    "for threshold in threshold_range:\n",
    "    preds = []\n",
    "    for prob in probs:\n",
    "        if prob[1] > threshold:\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    preds = np.array(preds)\n",
    "    accuracy = np.mean(np.equal(preds, val_data[1]))\n",
    "    f1 = f1_score(val_data[1], preds)\n",
    "    print(f'Prediction threshold = {threshold:.2f} - Validation accuracy: {accuracy*100:.4f}% - Validation f1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained('./model/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
